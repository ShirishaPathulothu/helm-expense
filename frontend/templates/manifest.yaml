apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: expense
  labels:
    app: frontend
    tier: web
    project: expense
spec:
  # modify replicas according to your case
  replicas: {{ .Values.deployment.replicas}}
  selector:
    matchLabels:
      app: frontend
      tier: web
      project: expense
  template:
    metadata:
      labels:
        app: frontend
        tier: web
        project: expense
    spec:
      containers:
      - name:  frontend
        image: shirisha02/frontend:{{ .Values.deployment.imageVersion}}
        resources:
          requests:
            memory: "100Mi"
            cpu: "120m"
          limits:
            memory: "128Mi"
            cpu: "120m"
---
apiVersion: v1
kind: Service
metadata:
  name: frontend
  namespace: expense
spec:
  type: LoadBalancer
  selector:
    app: frontend
    tier: web
    project: expense
  ports:
  - name: frontend-port
    protocol: TCP
    port: 80
    targetPort: 80     
---
apiVersion: autoscaling/v1
#apiVersion: autoscaling/v2beta2  # k8s 1.6+ - scale using the largest of multiple metrics
kind: HorizontalPodAutoscaler
metadata:
  name: frontend
  namespace: expense
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: {{.Values.hpa.cpuUtilization}} # by default in real time utilization percentage is 75         